{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vols = pd.read_csv(\"volumes.csv\")\n",
    "vols = vols.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = pd.read_csv(\"temperatures.csv\")\n",
    "temps = temps.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#headers = [\"Ru\", \"Rb\", \"Rh\", \"Be\", \"Ba\", \"Bi\", \"Br\", \"H\", \"P\", \"Ge\", \"Gd\", \"Ga\", \"Pr\", \"Pu\", \"C\",\\\n",
    "#\"Pd\", \"Cd\", \"Ho\", \"Mg\", \"Mo\", \"Mn\", \"O\", \"S\", \"Eu\", \"Zr\", \"Er\", \"Ni\",\\\n",
    "#\"Na\", \"Nb\", \"Nd\", \"Fe\", \"B\", \"F\", \"Sr\", \"N\", \"Si\", \"Sn\", \"Sm\", \"V\", \"Sc\", \"Sb\", \"Se\", \"Co\",\\\n",
    "#\"Cl\", \"Ca\", \"Ce\", \"Xe\", \"Cs\", \"Cr\", \"Cu\", \"La\", \"Li\", \"Tm\", \"Ti\", \"Te\", \"Tb\", \"Tc\", \"Yb\", \"Dy\",\\\n",
    "#\"I\", \"Y\", \"Ag\", \"Al\", \"As\", \"In\"]\n",
    "\n",
    "#headers = [\"H\",\"Li\",\"Be\",\"B\",\"C\",\"N\",\"O\",\"F\",\"Na\",\"Mg\",\"Al\",\"Si\",\"P\",\"S\",\"Cl\",\\\n",
    "#\"K\",\"Ca\",\"Sc\",\"Ti\",\"V\",\"Cr\",\"Mn\",\"Fe\",\"Co\",\"Ni\",\"Cu\",\"Zn\",\"Ga\",\\\n",
    "#\"Ge\",\"As\",\"Se\",\"Br\",\"Rb\",\"Sr\",\"Y\",\"Zr\",\"Nb\",\"Mo\",\\\n",
    "#\"Tc\",\"Ru\",\"Rh\",\"Pd\",\"Ag\",\"Cd\",\"In\",\"Sn\",\\\n",
    "#\"Sb\",\"Te\",\"I\",\"Xe\",\"Cs\",\"Ba\",\"La\",\"Ce\",\"Pr\",\\\n",
    "#\"Nd\",\"Sm\",\"Eu\",\"Gd\",\"Tb\",\"Dy\",\"Ho\",\"Er\",\\\n",
    "#\"Tm\",\"Yb\",\"Lu\",\"Hf\",\"Ta\",\"W\",\"Re\",\"Os\",\"Ir\",\\\n",
    "#\"Pt\",\"Au\",\"Hg\",\"Tl\",\"Pb\",\"Bi\",\"Ac\",\"Th\",\"Pa\",\\\n",
    "#\"U\",\"Np\",\"Am\"] #hofmann\n",
    "\n",
    "#headers = [\"Ru\", \"Rb\", \"Rh\", \"Be\", \"Ba\", \"Bi\", \"Br\", \"H\", \"P\", \"Ge\", \"Gd\", \"Ga\", \"Pr\", \"Pu\", \"C\",\\\n",
    "#\"Pd\", \"Cd\", \"Ho\", \"Mg\", \"Mo\", \"Mn\", \"O\", \"S\", \"Eu\", \"Zr\", \"Er\", \"Ni\",\\\n",
    "#\"Na\", \"Nb\", \"Nd\", \"Fe\", \"B\", \"F\", \"Sr\", \"N\", \"Si\", \"Sn\", \"Sm\", \"V\", \"Sc\", \"Sb\", \"Se\", \"Co\",\\\n",
    "#\"Cl\", \"Ca\", \"Ce\", \"Xe\", \"Cs\", \"Cr\", \"Cu\"]\n",
    "\n",
    "\n",
    "unitformula = pd.read_csv(\"scaledformulae.csv\")\n",
    "unitformula = unitformula.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "from scipy.optimize import nnls \n",
    "from sklearn.metrics import mean_squared_error\n",
    "huberVols = HuberRegressor(alpha=0.0005)\n",
    "huberAlpha = HuberRegressor()\n",
    "#regVols = linear_model.ElasticNet(positive = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new modelling method is being used, Huber regression is a method which is robust against outliers which have been encountered many times before.This method does not completely omit outliers, rather it weights them much less than inlier values. The alpha parameter is the same as before - a regularization parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions (Root mean square deviation & Percentage calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRMSD (y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "#w1 = [(3),(5),(10),(1)]\n",
    "#w2 = [(2),(4),(6),(8)]\n",
    "#getRMSD(w1,w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percCalc (row):\n",
    "    predictedvolume = row[\"Sum\"]\n",
    "    vols = row[\"Volume\"]\n",
    "    percentage = predictedvolume / vols\n",
    "    if (percentage >=0.95) and (percentage <=1.05):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.00\n",
    "#yarray = np.squeeze(np.array(vols.div(temps.Temperature*alpha+1, axis=\"index\")))\n",
    "huberVols.fit(unitformula,vols)\n",
    "weight = huberVols.coef_\n",
    "print zip(unitformula.columns.values, weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple version where the algorithm is not looped and nothing except the average element volumes are estimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.00\n",
    "x2=pd.DataFrame()\n",
    "for step in range(1,3):\n",
    "    print step\n",
    "    yarray = np.squeeze(np.array(vols.div(temps.Temperature*alpha+1, axis=\"index\")))\n",
    "    huberVols.fit(unitformula,yarray)\n",
    "    w = huberVols.coef_\n",
    "    for line in zip(unitformula.columns.values, w):\n",
    "        x2[line[0]] = unitformula[line[0]].apply(lambda x: x*line[1])\n",
    "    x2[\"Sum\"] = x2.sum(axis=1)\n",
    "    vol2 = vols.div(x2.Sum, axis=\"index\") - 1.0\n",
    "    huberAlpha.fit(temps, vol2)\n",
    "    alpha = huberAlpha.coef_\n",
    "    alpha = alpha[0]\n",
    "    print zip(unitformula.columns.values,w)\n",
    "    print alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version is more complex and alpha is introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = unitformula.columns.values\n",
    "unitformula[\"Keep\"] = 1\n",
    "weights = []\n",
    "alphas =[]\n",
    "fails = []\n",
    "for chunk in zip(unitformula.groupby(np.arange(len(unitformula)) // 10000),\\\n",
    "                 vols.groupby(np.arange(len(vols)) // 10000),\\\n",
    "                 temps.groupby(np.arange(len(temps)) // 10000)):\n",
    "    print \"\\nChunk: \", chunk[0][0]\n",
    "    prevalpha = 1\n",
    "    alpha = 0.00\n",
    "    RMSD = 100\n",
    "    chunkformula = chunk[0][1].reset_index(drop=True)\n",
    "    chunkvol = chunk[1][1].reset_index(drop=True)\n",
    "    chunktemp = chunk[2][1].reset_index(drop=True)\n",
    "    keepidx = np.arange(len(chunkformula)) #chunkformula.index.tolist()\n",
    "    i = 0\n",
    "    while abs(prevalpha-alpha) > 0.00001 or (RMSD > 1) :\n",
    "        try:\n",
    "            print \"\\t\" \"Iteration:\", i\n",
    "            print \"\\t\" \"Alpha: \", alpha, \"\\t\" \"deltaAlpha: \", abs(prevalpha-alpha), \"\\t\" \"RMSD: \", RMSD\n",
    "            if i > 0:\n",
    "                prevw = w\n",
    "            yarray = np.squeeze(np.array(chunkvol.iloc[keepidx].div(chunktemp.iloc[keepidx].Temperature*alpha+1, axis=\"index\")))\n",
    "            huberVols.fit(chunkformula[chunkformula.Keep == 1], yarray)\n",
    "            w = huberVols.coef_\n",
    "                            \n",
    "            if i > 0:\n",
    "                RMSD = getRMSD(prevw,w)\n",
    "        \n",
    "            x2=pd.DataFrame()\n",
    "            for line in zip(elements, w):\n",
    "                x2[line[0]] = chunkformula[line[0]].apply(lambda x: x*line[1])\n",
    "            x2[\"Sum\"] = x2.sum(axis=1)\n",
    "            vol2 = chunkvol.iloc[keepidx].div(x2.Sum.iloc[keepidx], axis=\"index\") - 1.0\n",
    "            huberAlpha.fit(chunktemp.iloc[keepidx], vol2)\n",
    "            if i > 0:\n",
    "                prevalpha = alpha\n",
    "            alpha = huberAlpha.coef_\n",
    "            alpha = alpha[0]\n",
    "            chunkformula[\"Keep\"] = pd.concat([x2,chunkvol], axis=1).apply(percCalc, axis=1)\n",
    "            keepidx = chunkformula[chunkformula[\"Keep\"] == 1].index.tolist()\n",
    "            \n",
    "            if (len(keepidx) <= 1) or (i > 100):\n",
    "                print \"Failure\"\n",
    "                fails.append([i, chunk[0][0]])\n",
    "                keepidx = [0]\n",
    "                break\n",
    "        except ValueError:\n",
    "            break\n",
    "        i +=1\n",
    "    if keepidx[0] != 0:\n",
    "        weights.append(w)#[0])\n",
    "        alphas.append(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the same algorithm as before, this time the model is set to Huber regression. The RMSD, absolute difference in alpha and percentage filter are applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs (histogram and kernel density) of volumes, average volumes etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vols.hist(bins=1000)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0,30000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tryw = np.array(weights_list)\n",
    "tryw = np.mean(tryw, axis=0)\n",
    "sns.distplot(tryw, bins = 10,kde=True)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating average element volume from array, standard deviation and standard mean error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print zip(elements, np.mean(weights,axis=0), np.std(weights, axis=0))\n",
    "av_vols =[]\n",
    "std =[]\n",
    "for value in zip(*(weights)):\n",
    "    temp =[]\n",
    "    for val in value:\n",
    "        if val != 0:\n",
    "            temp.append(val)\n",
    "    av_vols.append(np.array(temp).mean())\n",
    "    std.append(np.array(temp).std()/np.sqrt(len(temp)))\n",
    "for value in zip(elements, av_vols, std):\n",
    "    print value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"day\", y=\"total_bill\", data=av_vols)\n",
    "sns.plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[H: 5.08, Li: 22.6, Be: 36, B: 13.24, C: 13.87, N: 11.8,\\\n",
    "#O: 11.39, F: 11.17, Na: 26, Mg: 36, Al: 39.6, Si: 37.3, P: 29.5,\\\n",
    "#S: 25.2, Cl: 25.8, K: 36, Ca: 45, Sc: 42, Ti: 27.3, V: 24, Cr: 28.1,\\\n",
    "#Mn: 31.9, Fe: 30.4, Co: 29.4, Ni: 26, Cu: 26.9, Zn: 39, Ga: 37.8, Ge: 41.6, As: 36.4,\\\n",
    "#Se: 30.3, Br: 32.7, Rb: 42, Sr: 47, Y: 44, Zr: 27,\\\n",
    "#Nb: 37, Mo: 38, Tc: 38, Ru: 37.3, Rh: 31.2, Pd: 35, Ag: 35, Cd: 51, In: 55, Sn: 52.8,\\\n",
    "#Sb: 48, Te: 46.7, I: 46.2, Xe: 45, Cs: 46, Ba: 66, La: 58, Ce: 54, Pr: 57, Nd: 50, Sm: 50,\\ \n",
    "#Eu: 53, Gd: 56, Tb: 45, Dy: 50, Ho: 42, Er: 54, Tm: 49, Yb: 59]\n",
    "\n",
    "\n",
    "hofmw = np.array([37.3, 42, 31.2, 36, 13.24, 66, 32.7, 5.08, 29.5, 41.6, 56, 37.8, 57,\\\n",
    "13.87, 35, 51, 42, 36, 36, 38, 31.9, 11.39, 25.2, 39, 53, 27, 54, 26,\\\n",
    "26, 37, 50, 30.4, 13.24, 11.17, 47, 11.8, 37.3, 52.8, 50, 24, 42, 48, 30.3,\\\n",
    "29.4, 25.8, 45, 54, 45, 46, 28.1, 26.9, 58, 22.6, 49,\\\n",
    "27.3, 46.7, 45, 38, 59, 50, 46.2, 44, 35, 39.6, 36.4, 55])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating predicted volume of structures using hofmann values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = pd.DataFrame()\n",
    "for line in zip(elements, hofmw):\n",
    "        X3[line[0]] = unitformula[line[0]].apply(lambda x: x*line[1])\n",
    "hoffpred = X3.sum(axis=1)\n",
    "#print hoffpred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Methods\n",
    "Multiple methods of calculating similarity between hofmann predicted volume and volume from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "from scipy.spatial import distance\n",
    "cossimi = 1 - spatial.distance.cosine(hoffpred, vols)\n",
    "print cossimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucsimi = spatial.distance.euclidean(hoffpred, vols)\n",
    "print eucsimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mansimi = distance.minkowski(hoffpred, vols, 1) # manhattan distance \n",
    "chebsimi = distance.minkowski(hoffpred, vols, 3) # chebyshev distance\n",
    "print mansimi, chebsimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bray = 1 - distance.braycurtis(hoffpred, vols)\n",
    "print bray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canb = distance.canberra(hoffpred, vols)\n",
    "print canb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = distance.correlation(hoffpred, vols)\n",
    "print corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"The mean value of both our average volume: \", np.mean(w), \"and hofmann average volume: \", np.mean(hofmw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are slightly better/on par with the RANSAC method"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (2.7)",
   "language": "python",
   "name": "python2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
