{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vols = pd.read_csv(\"volumes300.csv\")\n",
    "vols = vols.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = pd.read_csv(\"temperatures300.csv\")\n",
    "temps = temps.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitformula = pd.read_csv(\"scaledformulae300.csv\")\n",
    "unitformula = unitformula.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoffX = pd.read_csv(\"hofmanndataframe.csv\")\n",
    "hoffX = hoffX.drop(\"Unnamed: 0\", axis=1)\n",
    "hoffy = pd.read_csv(\"hofmannvols.csv\")\n",
    "hoffy = hoffy.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, svm, kernel_ridge, ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from bokeh.plotting import figure, show, output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(unitformula, vols, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison methods functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcosine(estimator, X, y):\n",
    "    pred = estimator.predict(X)\n",
    "    cossimi = 1 - distance.cosine(pred,y)\n",
    "    return cossimi\n",
    "def getbray(estimator, X, y):\n",
    "    pred = estimator.predict(X)\n",
    "    bray = 1 - distance.braycurtis(pred, y)\n",
    "    return bray\n",
    "def getcanb(estimator, X, y):\n",
    "    pred = estimator.predict(X)\n",
    "    canb = distance.canberra(pred, y)\n",
    "    return canb\n",
    "def getcorr(estimator, X, y):\n",
    "    pred = estimator.predict(X)\n",
    "    corr = distance.correlation(pred, y)\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparison methods seen previously have been cleaned up and made into separate functions so they can be called from each loop below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2 = linear_model.LinearRegression(fit_intercept=False)\n",
    "reg2.fit(hoffX,hoffy)\n",
    "hoffpred = reg2.predict(unitformula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous mistake has been resolved; now the Hofmann values are read and fit to a simple linear model so that each element is given its predetermined volume value.\n",
    "Thereafter a prediction of the volumes is made by using the predict function, and predicting based off the unit formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoffpredDF = pd.DataFrame(hoffpred)\n",
    "hoffpredDF.hist(bins=1000)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0,30000])\n",
    "plt.ylabel(\"Number of entries\")\n",
    "plt.xlabel(\"Volume\")\n",
    "#plt.set_title(\"Volume of entries\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions can then be graphically seen in a histogram, to see which range of volumes were the most predicted, the max etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print reg2.score(unitformula,vols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hofmann prediction is scored against the actual volumes and this result is seen to be poor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoffCV= cross_val_score(reg2,hoffX,hoffy, cv=5)\n",
    "print hoffCV.mean(), hoffCV.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is scored again but using cross validation (5 times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoffcvcosine = cross_val_score(reg2, unitformula, vols, cv=5, scoring=getcosine)\n",
    "hoffcvbray = cross_val_score(reg2, unitformula, vols, cv=5, scoring=getbray)\n",
    "hoffcvcanb = cross_val_score(reg2, unitformula, vols, cv=5, scoring=getcanb)\n",
    "hoffcvcorr = cross_val_score(reg2, unitformula, vols, cv=5, scoring=getcorr)\n",
    "print hoffcvcosine.mean() , hoffcvcosine.std(),hoffcvcosine\n",
    "print \"\\n\", hoffcvbray.mean(), hoffcvbray.std(), hoffcvbray\n",
    "print \"\\n\", hoffcvcanb.mean(), hoffcvcanb.std(),hoffcvcanb\n",
    "print \"\\n\", hoffcvcorr.mean(), hoffcvcorr.std(), hoffcvcorr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similarity of the Hofmann predictions vs. the actual volumes is calculated using each of the functions above; these results are cross validated 5 times and the mean score and standard deviations are outputted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regHub = linear_model.HuberRegressor(alpha=0.0005)\n",
    "hubcosine = cross_val_score(regHub, unitformula, vols, cv=5, scoring=getcosine)\n",
    "hubbray = cross_val_score(regHub, unitformula, vols, cv=5, scoring=getbray)\n",
    "hubcanb = cross_val_score(regHub, unitformula, vols, cv=5, scoring=getcanb)\n",
    "hubcorr = cross_val_score(regHub, unitformula, vols, cv=5, scoring=getcorr)\n",
    "\n",
    "#print \"\\nMy Mean: \", cvscore.mean(), \"STD: \", cvscore.std()\n",
    "print \"\\nCosine mean: \", hubcosine.mean(), \"Standard deviation: \", hubcosine.std(), hubcosine\n",
    "print \"\\nBray Similarity: \", hubbray.mean(), \"Standard deviation: \", hubbray.std(), hubbray\n",
    "print \"\\n Canberra Similarity: \", hubcanb.mean(), \"Standard deviation: \", hubcanb.std(), hubcanb\n",
    "print \"\\n Correlation: \", hubcorr.mean(), \"Standard deviation: \", hubcorr.std(), hubcorr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the same is being employed for the Huber regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim = [(linear_model.RANSACRegressor(linear_model.LinearRegression())),\\\n",
    "          (linear_model.RANSACRegressor(linear_model.Ridge(alpha=100))), (RandomForestRegressor(n_estimators=100, n_jobs=-1)),\\\n",
    "          (ensemble.GradientBoostingRegressor(n_estimators=100)), (ensemble.ExtraTreesRegressor(n_estimators=100, n_jobs=-1))]\n",
    "\n",
    "for reg in estim:\n",
    "    cvscore = cross_val_score(reg, unitformula, vols)\n",
    "    cvcosine = cross_val_score(reg, unitformula, vols, cv=5, scoring=getcosine)\n",
    "    cvbray = cross_val_score(reg, unitformula, vols, cv=5, scoring=getbray)\n",
    "    cvcanb = cross_val_score(reg, unitformula, vols, cv=5, scoring=getcanb)\n",
    "    cvcorr = cross_val_score(reg, unitformula, vols, cv=5, scoring=getcorr)\n",
    "    #pred = cross_val_predict(reg, unitformula, vols)\n",
    "\n",
    "    print \"\\nMy Mean: \", cvscore.mean(), \"STD: \", cvscore.std()\n",
    "    print \"\\nCosine mean: \", cvcosine.mean(), \"Standard deviation: \", cvcosine.std(), cvcosine\n",
    "    print \"\\nBray Similarity: \", cvbray.mean(), \"Standard deviation: \", cvbray.std(), cvbray\n",
    "    print \"\\n Canberra Similarity: \", cvcanb.mean(), \"Standard deviation: \", cvcanb.std(), cvcanb\n",
    "    print \"\\n Correlation: \", cvcorr.mean(), \"Standard deviation: \", cvcorr.std(), cvcorr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a loop to perform the same calculations but over a range of estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim = [(linear_model.RANSACRegressor(linear_model.LinearRegression())),\\\n",
    "          (linear_model.RANSACRegressor(linear_model.Ridge(alpha=100))), (RandomForestRegressor(n_estimators=100, n_jobs=-1)),\\\n",
    "          (ensemble.GradientBoostingRegressor(n_estimators=100)), (ensemble.ExtraTreesRegressor(n_estimators=100, n_jobs=-1))]\n",
    "\n",
    "from scipy import spatial\n",
    "from scipy.spatial import distance\n",
    "\n",
    "for reg in estim:\n",
    "    print \"\\nUsing: \", reg\n",
    "    cvscore = cross_val_score(reg, unitformula, vols)\n",
    "    #hofcvscore = cross_val_score(reg, hoffX, hoffy)\n",
    "    pred = cross_val_predict(reg, unitformula, vols)\n",
    "    \n",
    "        \n",
    "    predDF = pd.DataFrame(pred, columns = [\"Pred Vol\"])\n",
    "    predDF[\"Pred Vol\"].div(vols[\"Volume\"]).hist(bins=50)\n",
    "    print predDF[\"Pred Vol\"].div(vols[\"Volume\"]).describe()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loop is just to create histograms based off of the ratio between the predictions made by the estimators and the actual volumes in the CSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hoffDF = pd.DataFrame(hoffpred, columns = [\"Hoff Vol\"])\n",
    "hoffDF[\"Hoff Vol\"].div(vols[\"Volume\"]).hist(bins=50)\n",
    "print hoffDF[\"Hoff Vol\"].div(vols[\"Volume\"]).describe()\n",
    "plt.show()\n",
    "plt.title(\"Hoffman & CSD Volumes\")\n",
    "plt.xlabel(\"Volume ratio\")\n",
    "plt.ylabel(\"Count\")\n",
    "##HOFFMAN VS OG VOL; problems with seaborn plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same idea - creating graphs but this is for the ratio between the Hofmann predicted volumes & actual volumes from CSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "estim = [(linear_model.RANSACRegressor(linear_model.LinearRegression())),\\\n",
    "          (linear_model.RANSACRegressor(linear_model.Ridge(alpha=100))), (RandomForestRegressor(n_estimators=100, n_jobs=-1)),\\\n",
    "          (ensemble.GradientBoostingRegressor(n_estimators=100)), (ensemble.ExtraTreesRegressor(n_estimators=100, n_jobs=-1))]\n",
    "for reg in estim:\n",
    "    print \"\\nUsing: \", reg\n",
    "    pred = cross_val_predict(reg, unitformula, vols)\n",
    "    predDF = pd.DataFrame(pred, columns = [\"Pred Vol\"])\n",
    "    hoffDF[\"Hoff Vol\"].div(predDF[\"Pred Vol\"]).hist(bins=50)\n",
    "    print hoffDF[\"Hoff Vol\"].div(predDF[\"Pred Vol\"]).describe()\n",
    "    plt.show()\n",
    "    plt.title(\"Hoffman & Huseyin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again creating a graph, this time for the ratio between the Hofmann predicted volumes & volumes predicted from each regressor. This is a separate loop just so the graphs aren't confusing to view"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (2.7)",
   "language": "python",
   "name": "python2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
