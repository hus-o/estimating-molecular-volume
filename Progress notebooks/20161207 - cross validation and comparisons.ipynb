{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vols = pd.read_csv(\"volumes300.csv\")\n",
    "vols = vols.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temps = pd.read_csv(\"temperatures300.csv\")\n",
    "temps = temps.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#headers = [\"Ru\", \"Rb\", \"Rh\", \"Be\", \"Ba\", \"Bi\", \"Br\", \"H\", \"P\", \"Ge\", \"Gd\", \"Ga\", \"Pr\", \"Pu\", \"C\",\\\n",
    "#\"Pd\", \"Cd\", \"Ho\", \"Mg\", \"Mo\", \"Mn\", \"O\", \"S\", \"Eu\", \"Zr\", \"Er\", \"Ni\",\\\n",
    "#\"Na\", \"Nb\", \"Nd\", \"Fe\", \"B\", \"F\", \"Sr\", \"N\", \"Si\", \"Sn\", \"Sm\", \"V\", \"Sc\", \"Sb\", \"Se\", \"Co\",\\\n",
    "#\"Cl\", \"Ca\", \"Ce\", \"Xe\", \"Cs\", \"Cr\", \"Cu\", \"La\", \"Li\", \"Tm\", \"Ti\", \"Te\", \"Tb\", \"Tc\", \"Yb\", \"Dy\",\\\n",
    "#\"I\", \"Y\", \"Ag\", \"Al\", \"As\", \"In\"]\n",
    "\n",
    "headers = [\"H\",\"Li\",\"Be\",\"B\",\"C\",\"N\",\"O\",\"F\",\"Na\",\"Mg\",\"Al\",\"Si\",\"P\",\"S\",\"Cl\",\\\n",
    "\"K\",\"Ca\",\"Sc\",\"Ti\",\"V\",\"Cr\",\"Mn\",\"Fe\",\"Co\",\"Ni\",\"Cu\",\"Zn\",\"Ga\",\\\n",
    "\"Ge\",\"As\",\"Se\",\"Br\",\"Rb\",\"Sr\",\"Y\",\"Zr\",\"Nb\",\"Mo\",\\\n",
    "\"Tc\",\"Ru\",\"Rh\",\"Pd\",\"Ag\",\"Cd\",\"In\",\"Sn\",\\\n",
    "\"Sb\",\"Te\",\"I\",\"Xe\",\"Cs\",\"Ba\",\"La\",\"Ce\",\"Pr\",\\\n",
    "\"Nd\",\"Sm\",\"Eu\",\"Gd\",\"Tb\",\"Dy\",\"Ho\",\"Er\",\\\n",
    "\"Tm\",\"Yb\",\"Lu\",\"Hf\",\"Ta\",\"W\",\"Re\",\"Os\",\"Ir\",\\\n",
    "\"Pt\",\"Au\",\"Hg\",\"Tl\",\"Pb\",\"Bi\",\"Ac\",\"Th\",\"Pa\",\\\n",
    "\"U\",\"Np\",\"Am\"] #hofmann\n",
    "\n",
    "#headers = [\"Ru\", \"Rb\", \"Rh\", \"Be\", \"Ba\", \"Bi\", \"Br\", \"H\", \"P\", \"Ge\", \"Gd\", \"Ga\", \"Pr\", \"Pu\", \"C\",\\\n",
    "#\"Pd\", \"Cd\", \"Ho\", \"Mg\", \"Mo\", \"Mn\", \"O\", \"S\", \"Eu\", \"Zr\", \"Er\", \"Ni\",\\\n",
    "#\"Na\", \"Nb\", \"Nd\", \"Fe\", \"B\", \"F\", \"Sr\", \"N\", \"Si\", \"Sn\", \"Sm\", \"V\", \"Sc\", \"Sb\", \"Se\", \"Co\",\\\n",
    "#\"Cl\", \"Ca\", \"Ce\", \"Xe\", \"Cs\", \"Cr\", \"Cu\"]\n",
    "\n",
    "\n",
    "unitformula = pd.read_csv(\"scaledformulae300.csv\", usecols=headers)\n",
    "#unitformula = unitformula.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen there has been a change to the csv files being used; it has been further filtered of things such as disordered structures; those with a R factor of over 10%; polymeric structures etc.\n",
    "\n",
    "This brings the total entries being used from around 500,000 to 300,000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, svm, kernel_ridge, ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross_val_score is a scoring method where similar to the train_test_split the data is sectioned off. In cross validation the test set is picked randomly from the dataset; this is repeated multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hoffX = pd.read_csv(\"hofmanndataframe.csv\")\n",
    "hoffy = pd.read_csv(\"hofmannvols.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hofmann values have been collated as a csv file with the goal of calculating predicted volumes & scoring it, in a different way to before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(unitformula, vols, random_state=24)\n",
    "hoffX_train, hoffX_test, hoffy_train, hoffy_test = train_test_split(hoffX, hoffy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estim = [(linear_model.RANSACRegressor(linear_model.LinearRegression())),\\\n",
    "          (linear_model.RANSACRegressor(linear_model.Ridge(alpha=100))), (RandomForestRegressor()),\\\n",
    "          (ensemble.GradientBoostingRegressor()), (ensemble.ExtraTreesRegressor(n_estimators=100, n_jobs=-1))]\n",
    "#try huber too\n",
    "\n",
    "for reg in estim:\n",
    "    print \"\\nUsing: \", reg\n",
    "    scores = cross_val_score(reg, unitformula, vols)\n",
    "    print \"\\nMean: \", scores.mean(), \"STD: \", scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loop is not using TTS rather the whole dataset is read and the scores are cross validated; this is looped for each regressor. The average score and standard deviation are outputted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = [(linear_model.RANSACRegressor(linear_model.LinearRegression())),\\\n",
    "             (linear_model.RANSACRegressor(linear_model.Ridge(alpha=100))), (RandomForestRegressor()),\\\n",
    "             (ensemble.GradientBoostingRegressor()), (ensemble.ExtraTreesRegressor())]\n",
    "for reg in estimator:\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(unitformula, vols, random_state = 24)\n",
    "    reg.fit(X_train, y_train)\n",
    "    pdv = reg.predict(X_test)\n",
    "    print \"Using: \", reg\n",
    "    print reg.score(X_test,y_test)\n",
    "    pdvd = pd.DataFrame(pdv, columns = [\"Pred Vol\"])\n",
    "    ytest = pd.DataFrame(y_test)\n",
    "    ytest = ytest.reset_index(drop=True)\n",
    "    pdvd[\"Pred Vol\"].div(ytest[\"Volume\"]).hist(bins=50)\n",
    "    print pdvd[\"Pred Vol\"].div(ytest[\"Volume\"]).describe()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loop is the same as the ones seen previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg2 = ensemble.ExtraTreesRegressor(n_estimators=100, n_jobs=-1)\n",
    "reg2.fit(hoffX_test,hoffy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print reg2.score(hoffX_test, hoffy_test)\n",
    "pdhv = reg2.predict(hoffX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdhvd = pd.DataFrame(pdhv, columns = [\"Pred Vol\"])\n",
    "hoffytest = pd.DataFrame(hoffy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoffytest.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdhvd[\"Pred Vol\"].div(hoffytest[\"HofmannVols\"]).hist(bins=50)\n",
    "print pdhvd[\"Pred Vol\"].div(hoffytest[\"HofmannVols\"]).describe()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This was an attempt at fitting, predicting and scoring the Hofmann values using TTS; this was an incorrect way to carry the experiment out as the Hofmann values are already known and to score it against itself would yield a score of 1; this needed to be changed to unitformula & vols"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (2.7)",
   "language": "python",
   "name": "python2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
