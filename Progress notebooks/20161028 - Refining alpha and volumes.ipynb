{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vols = pd.read_csv(\"volumes.csv\", nrows=10000)\n",
    "vols = vols.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(\"temperatures.csv\", nrows=10000)\n",
    "temp = temp.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitformula = pd.read_csv(\"scaledformulae.csv\", nrows=10000)\n",
    "unitformula = unitformula.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unitformula is from before (the scaled formula that was parsed and calculated), in a file format over around 500,000 entries. The corresponding volumes and temperatures were also filtered and placed in separate files (these files weren't made entirely by me, some were sourced from my supervisor).\n",
    "\n",
    "Also the number of rows is being kept to 10,000 in this case due to memory issues - to keep things fast and smooth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, svm\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(unitformula,vols)\n",
    "w = reg.coef_\n",
    "#w =np.matrix(w)\n",
    "print w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the model is fitted and the average element volumes are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.00\n",
    "x2=pd.DataFrame()\n",
    "for line in zip(unitformula.columns.values, w[0]):\n",
    "    x2[line[0]] = unitformula[line[0]].apply(lambda x: x*line[1])\n",
    "    \n",
    "predictedvolume = x2.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple begining to the algorithm adapted from equations from Hofmann's paper (fast crystal density estimation)\n",
    "\n",
    "To make a first estimation alpha is set to 0.\n",
    "\n",
    "This loop simply predicts the volume based on the average element volumes (from above, labeled as \"w\"), by multiplying it with the corresponding amount of the element, for example C2H5 > C:2, H:5 > 2 x12 , 5x5 (where the volume of C is 12 and H is 5). \n",
    "\n",
    "These are them summed (x2.sum) to get a total volume of the molecule based on its formula (predictedvolume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print np.array(predictedvolume)-np.array(vols)\n",
    "difvol = predictedvolume.values - vols.values\n",
    "#print zip(unitformula.columns.values, difvol)\n",
    "print difvol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is a simple (and poor) method of comparison, a simple subtraction to show the gap between the predicted volumes and the actual volumes"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (2.7)",
   "language": "python",
   "name": "python2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
